// swift-interface-format-version: 1.0
// swift-compiler-version: Apple Swift version 5.7.2 (swiftlang-5.7.2.135.5 clang-1400.0.29.51)
// swift-module-flags: -target arm64-apple-ios14.0 -enable-objc-interop -enable-library-evolution -swift-version 5 -enforce-exclusivity=checked -O -module-name Ultralytics
// swift-module-flags-ignorable: -enable-bare-slash-regex
import AVFoundation
import CoreML
import CoreVideo
import Foundation
import Swift
import UIKit
@_exported import Ultralytics
import Vision
import _Concurrency
import _StringProcessing
public enum UltralyticsBaseModel : Swift.String {
  case coco_n
  public init?(rawValue: Swift.String)
  public typealias RawValue = Swift.String
  public var rawValue: Swift.String {
    get
  }
}
public class BaseModel : Ultralytics.YoloModel {
  public init(ultralyticsBaseModel: Ultralytics.UltralyticsBaseModel)
  public func loadModel() -> CoreML.MLModel?
  public typealias MLModel = CoreML.MLModel
  @objc deinit
}
public protocol VideoCaptureDelegate : AnyObject {
  func videoCapture(_ capture: Ultralytics.VideoCapture, didCaptureVideoFrame: CoreMedia.CMSampleBuffer)
}
@objc @_inheritsConvenienceInitializers public class VideoCapture : ObjectiveC.NSObject {
  public var previewLayer: AVFoundation.AVCaptureVideoPreviewLayer?
  weak public var delegate: Ultralytics.VideoCaptureDelegate?
  public func setUp(sessionPreset: AVFoundation.AVCaptureSession.Preset = .hd1280x720, completion: @escaping (Swift.Bool) -> Swift.Void)
  public func start()
  public func stop()
  public func capturePicture() -> UIKit.UIImage?
  @objc override dynamic public init()
  @objc deinit
}
extension Ultralytics.VideoCapture : AVFoundation.AVCaptureVideoDataOutputSampleBufferDelegate {
  @objc dynamic public func captureOutput(_ output: AVFoundation.AVCaptureOutput, didOutput sampleBuffer: CoreMedia.CMSampleBuffer, from connection: AVFoundation.AVCaptureConnection)
}
extension Ultralytics.VideoCapture : AVFoundation.AVCapturePhotoCaptureDelegate {
  @available(iOS 11.0, *)
  @objc dynamic public func photoOutput(_ output: AVFoundation.AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVFoundation.AVCapturePhoto, error: Swift.Error?)
}
public protocol Listener {
  func on(recognitions: [[Swift.String : Any]])
}
public class ObjectDetector {
  public init(yoloModel: Ultralytics.YoloModel, imageSize: CoreFoundation.CGSize)
  public func predict(sampleBuffer: CoreMedia.CMSampleBuffer, onCompleteListener: Ultralytics.Listener)
  @objc deinit
}
public protocol YoloModel {
  associatedtype MLModel
  func loadModel() -> Self.MLModel?
}
extension Ultralytics.UltralyticsBaseModel : Swift.Equatable {}
extension Ultralytics.UltralyticsBaseModel : Swift.Hashable {}
extension Ultralytics.UltralyticsBaseModel : Swift.RawRepresentable {}
